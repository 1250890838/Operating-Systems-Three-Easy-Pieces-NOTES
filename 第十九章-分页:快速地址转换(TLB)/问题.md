1. 为了计时,可能需要一个计时器,例如gettimeofday提供的。这种计时器的精度如何?操作要花多少时间,才能让你对它精确计时?(这有助于确定需要循环多少次,反复访问内存页,才能对它成功计时。)

2. 写一个程序,命名为tlb.c,大体测算一下每个页的平均访问时间。程序的输入参数有:页的数目和尝试的次数。

3. 用你喜欢的脚本语言(csh、 Python等写一段脚本来运行这个程序,当访问页面从1增长到几千,也许每次迭代都乘2。在不同的机器上运行这段脚本,同时收集相应数据。需要试多少次才能获得可信的测量结果?

4. 接下来,将结果绘图,类似于上图。可以用 ploticus这样的好工具画图。可视化使数据更容易理解,你认为是什么原因?

5. 要注意编译器优化带来的影响。编译器做各种聪明的事情,包括优化掉循环,如果循环中增加的变量后续没有使用。如何确保编译器不优化掉你写的TLB大小测算程序的主循环?

6. 还有一个需要注意的地方,今天的计算机系统大多有多个CPU,每个CPU当然有自己的TLB结构。为了得到准确的测量数据我们需要只在一个CPU上运行程序,避免调度器把进程从一个CPU调度到另一个去运行。如何做到?(提示:在 Google上搜索“ pinningthread”相关的信息)如果没有这样做,代码从一个CPU移到了另一个,会发生什么情况?

7. 另一个可能发生的问题与初始化有关。如果在访问数组a之前没有初始化,第一次访问将非常耗时,由于初始访问开销,比如要求置0。这会影响你的代码及其计时吗?如何抵消这些潜在的开销?